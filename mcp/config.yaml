# 3-Stage Retrieval Pipeline Configuration

# General pipeline settings
pipeline:
  device: "cuda"  # cuda, cpu, auto
  cache_dir: "./models"
  index_dir: "./faiss_index"
  log_level: "DEBUG"
  log_file: "retrieval_pipeline.log"
  enable_timing: true
  save_intermediate_results: false
  auto_cleanup: true
  max_memory_usage_gb: 4.0
  
  # Stage 1: Fast Candidate Generation
  stage1:
    model: "google/embeddinggemma-300m"
    top_k: 500
    batch_size: 32
    max_text_length: 512
    enable_bm25: true
    bm25_top_k: 300
    fusion_method: "rrf"  # "rrf" or "weighted"
    use_fp16: true
    # Reciprocal Rank Fusion parameters
    rrf_k: 60
    dense_weight: 0.7
    bm25_weight: 0.3
    # FAISS parameters
    nlist: 100  # IVF clusters
    nprobe: 10  # search probes
    
  # Stage 2: Multi-Vector Rescoring
  stage2:
    model: "lightonai/GTE-ModernColBERT-v1"
    top_k: 100
    batch_size: 16
    max_seq_length: 192  # Optimized for 4GB VRAM
    use_fp16: true
    scoring_method: "maxsim"  # "maxsim" or "colbert"
    pooling_method: "cls"  # "cls", "mean", or "max"
    normalize_embeddings: true
    use_gpu_if_available: true
    
  # Stage 3: Cross-Encoder Reranking
  stage3:
    model: "cross-encoder/ms-marco-MiniLM-L6-v2"
    top_k: 20
    batch_size: 32
    max_length: 256  # Optimized for 4GB VRAM
    use_fp16: true
    use_gpu_if_available: true
    activation_fxn: "sigmoid"  # "sigmoid" or "softmax"
    normalize_scores: true